{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d336d6e3",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8082910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def positional_encoding(max_len, d_model):\n",
    "    # max_len: độ dài tối đa của 1 chuỗi\n",
    "    # d_model: kích thước embedding\n",
    "    pe = np.zeros((max_len, d_model))\n",
    "    for pos in range(max_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            angle = pos / (10000 ** (i / d_model))\n",
    "            # Vị trí chẵn\n",
    "            pe[pos, i] = math.sin(angle)\n",
    "            # Vị trí lẻ\n",
    "            pe[pos, i+1] = math.cos(angle)\n",
    "    return pe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f751a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma trận ban đầu:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "------------------\n",
      "ma trận positional encoding:\n",
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      " [ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      " [-0.7568025  -0.65364362  0.03998933  0.99920011]]\n",
      "--------------------------\n",
      "vector PE cho vị trí thứ: 0 là:\n",
      "[0. 1. 0. 1.]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 1 là:\n",
      "[0.84147098 0.54030231 0.00999983 0.99995   ]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 2 là:\n",
      "[ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 3 là:\n",
      "[ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 4 là:\n",
      "[-0.7568025  -0.65364362  0.03998933  0.99920011]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_len = 5\n",
    "d_model = 4\n",
    "pe = np.zeros((5, 4))\n",
    "print(f\"ma trận ban đầu:\\n{pe}\")\n",
    "print(f\"------------------\")\n",
    "for pos in range(max_len):\n",
    "    for i in range(0, d_model, 2):\n",
    "        angle = pos / (10000 ** (i / d_model))\n",
    "        pe[pos][i] = math.sin(angle)\n",
    "        pe[pos][i+1] = math.cos(angle)\n",
    "print(f\"ma trận positional encoding:\\n{pe}\")\n",
    "print(f\"--------------------------\")\n",
    "for i in range(max_len):\n",
    "    print(f\"vector PE cho vị trí thứ: {i} là:\\n{pe[i]}\")\n",
    "    print(f\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51dc3c",
   "metadata": {},
   "source": [
    "Sau khi tính PE, ta cộng vào embedding ban đầu: X' = X + PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a83c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector embedding của input:\n",
      "[[-0.45413692  0.29019407 -1.34147064 -0.23869127]\n",
      " [-0.57477958 -1.12945031 -0.51195096  0.55844638]\n",
      " [ 0.40192628 -0.10812314 -0.32817709  0.60401348]\n",
      " [ 1.30145968  1.36210844  1.55611376  0.21600585]\n",
      " [ 1.71018055  0.94075442  0.88960112 -1.40731508]]\n",
      "---------------------------------\n",
      "vector x khi thêm positional encoding:\n",
      "[[-0.45413692  1.29019407 -1.34147064  0.76130873]\n",
      " [ 0.2666914  -0.58914801 -0.50195113  1.55839638]\n",
      " [ 1.31122371 -0.52426998 -0.30817842  1.60381348]\n",
      " [ 1.44257969  0.37211594  1.58610926  1.21555589]\n",
      " [ 0.95337806  0.2871108   0.92959046 -0.40811497]]\n"
     ]
    }
   ],
   "source": [
    "# Giả sử vector X ban đầu có giá trị:\n",
    "x = np.random.randn(max_len, d_model)\n",
    "print(f\"vector embedding của input:\\n{x}\")\n",
    "x = x + pe\n",
    "print(f\"---------------------------------\")\n",
    "print(f\"vector x khi thêm positional encoding:\\n{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffcdde",
   "metadata": {},
   "source": [
    "Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf922d",
   "metadata": {},
   "source": [
    "Residual and Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013da2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Layer normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # gamma và beta\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased= False)\n",
    "\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d09530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1:\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
      "gamma2:\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "---------------------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "d_model = 5\n",
    "gamma1 = nn.Parameter(torch.zeros(d_model))\n",
    "gamma2 = torch.zeros(d_model)\n",
    "print(f\"gamma1:\\n{gamma1}\")\n",
    "print(f\"gamma2:\\n{gamma2}\")\n",
    "print(f\"---------------------------\")\n",
    "matrix = torch.zeros(3,4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b39125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1232, -0.3697, -0.1003,  0.4852, -2.1945],\n",
      "         [ 1.6909, -1.5506, -0.3908, -1.5257, -1.9677],\n",
      "         [ 1.0208,  1.4066, -1.7473, -1.0091, -1.5697]],\n",
      "\n",
      "        [[ 2.3933, -1.4482, -1.0889, -0.4912, -1.3202],\n",
      "         [ 0.7352, -0.1250, -0.0594, -2.1032,  1.2380],\n",
      "         [-0.3301,  0.2461,  0.6317, -1.0883, -0.2924]]])\n",
      "Trung bình của từng hàng: \n",
      "tensor([[[-0.4112],\n",
      "         [-0.7488],\n",
      "         [-0.3797]],\n",
      "\n",
      "        [[-0.3910],\n",
      "         [-0.0629],\n",
      "         [-0.1666]]])\n",
      "Phương sai của từng hàng:\n",
      "tensor([[[0.8735],\n",
      "         [1.7625],\n",
      "         [1.7669]],\n",
      "\n",
      "        [[2.0461],\n",
      "         [1.2992],\n",
      "         [0.3399]]])\n"
     ]
    }
   ],
   "source": [
    "# Tạo input gồm 2 câu batch_size = 2\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "d_model = 5\n",
    "x = torch.randn(batch_size,seq_len, d_model)\n",
    "print(x)\n",
    "mean = x.mean(dim=-1, keepdim=True)\n",
    "print(f\"Trung bình của từng hàng: \\n{mean}\")\n",
    "var = x.var(dim = -1, keepdim=True, unbiased=False)\n",
    "print(f\"Phương sai của từng hàng:\\n{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7337264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\n",
      "tensor([-1.5260,  1.7643, -2.1167,  0.8053, -0.8014])\n",
      "Chuẩn hóa các giá trị của input:\n",
      "tensor([[[ 0.5718,  0.0444,  0.3326,  0.9591, -1.9080],\n",
      "         [ 1.8377, -0.6040,  0.2697, -0.5852, -0.9181],\n",
      "         [ 1.0536,  1.3439, -1.0288, -0.4734, -0.8952]],\n",
      "\n",
      "        [[ 1.9465, -0.7390, -0.4879, -0.0700, -0.6496],\n",
      "         [ 0.7002, -0.0545,  0.0030, -1.7900,  1.1413],\n",
      "         [-0.2805,  0.7079,  1.3692, -1.5808, -0.2158]]])\n",
      "Đầu ra layernorm của input:\n",
      "tensor([[[-2.3986,  1.8426, -2.8208,  1.5777,  0.7277],\n",
      "         [-4.3302,  0.6987, -2.6875,  0.3340, -0.0656],\n",
      "         [-3.1337,  4.1353,  0.0609,  0.4241, -0.0840]],\n",
      "\n",
      "        [[-4.4963,  0.4604, -1.0839,  0.7490, -0.2808],\n",
      "         [-2.5944,  1.6682, -2.1231, -0.6362, -1.7160],\n",
      "         [-1.0979,  3.0132, -5.0149, -0.4677, -0.6284]]])\n"
     ]
    }
   ],
   "source": [
    "gamma = torch.randn(d_model)\n",
    "print(f\"gamma:\\n{gamma}\")\n",
    "x_hat = (x - mean) / torch.sqrt(var + 1e-6)\n",
    "print(f\"Chuẩn hóa các giá trị của input:\\n{x_hat}\")\n",
    "ans = gamma * x_hat + gamma\n",
    "print(f\"Đầu ra layernorm của input:\\n{ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c54316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sublayer: Feed forward network: 2 hidden layer\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424690fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "d_model = 4\n",
    "d_ff = 6\n",
    "linear1 = nn.Linear(d_model, d_ff)\n",
    "print(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370ee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual connection Layernorm\n",
    "class SublayerConnection(nn.Module):\n",
    "    # y = layernorm(x + sublayer(x))\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, sublayer):\n",
    "        output = self.norm(x + self.dropout(sublayer(x)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7635e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.3, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.3)\n",
    "print(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c90af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[[-0.6801,  0.2333,  0.4238, -0.4792,  0.2576, -0.5232],\n",
      "         [ 0.1243, -0.6267,  0.5940,  0.6381, -0.4827, -0.2550],\n",
      "         [ 0.5542,  0.0287, -0.9203, -0.8005,  0.1908,  0.8928],\n",
      "         [-0.3720, -2.0090,  0.0971,  1.3827, -2.2678, -0.2903]]])\n",
      "output của x khi đi qua residual + layer normalization:\n",
      "tensor([[[-0.9000, -0.3499,  1.7484, -0.3912,  0.9087, -1.0159],\n",
      "         [ 0.2296, -1.6538,  1.3579,  0.9629, -0.3083, -0.5883],\n",
      "         [ 1.0469, -0.7939, -0.9680, -1.2083,  0.8452,  1.0781],\n",
      "         [ 0.1839, -1.3701,  1.0333,  1.3823, -1.0359, -0.1936]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# y = layernorm(x + sublayer(x))\n",
    "# Giả sử input x là 1 câu có 4 từ, mỗi từ được mã hóa thành vector 6 chiều\n",
    "# ma trận embedding\n",
    "x = torch.randn(1, 4, 6)\n",
    "print(f\"input:\\n{x}\")\n",
    "sublayer = FeedForward(d_model=6, d_ff=10)\n",
    "sublayer_connection = SublayerConnection(6)\n",
    "y = sublayer_connection(x, sublayer)\n",
    "print(f\"output của x khi đi qua residual + layer normalization:\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd7631",
   "metadata": {},
   "source": [
    "Cài đặt MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c398eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # softmax theo hàng\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x/np.sum(e_x, axis=-1, keepdims=True)\n",
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    # Q: (n, d_k) - n query vectors\n",
    "    # K: (m, d_k) - m key vectors\n",
    "    # V: (m, d_v) - m value vectors\n",
    "    # Lấy ra d_k cho bước tính căn bậc 2\n",
    "    d_k = Q.shape[1]\n",
    "    # Tính score\n",
    "    scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n",
    "    # Tính trọng số attention\n",
    "    weights = softmax(scores)\n",
    "    # Tổ hợp tuyến tính với V\n",
    "    output = np.matmul(weights, V)\n",
    "    return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2de02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        # d_model phải chia hết cho num_heads\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        # Khởi tạo ma trận trọng số\n",
    "        self.W_Q = np.random.randn(d_model, d_model)\n",
    "        self.W_K = np.random.randn(d_model, d_model)\n",
    "        self.W_V = np.random.randn(d_model, d_model)\n",
    "        # Ma trận trọng số được sử dụng cuối cùng\n",
    "        self.W_O = np.random.randn(d_model, d_model)\n",
    "    def split_heads(self, x):\n",
    "        # x: (seq_len, d_model)\n",
    "        # return: (num_heads, seq_len, d_k)\n",
    "        seq_len = x.shape[0]\n",
    "        # Tách X thành 1 mảng gồm seq_len ma trận, mỗi ma trận có num_heads hàng, d_k cột\n",
    "        x = x.reshape(seq_len, self.num_heads, self.d_k)\n",
    "    def combine_heads(self, x):\n",
    "        # x: (num_heads, seq_len, d_k)\n",
    "        # return: (seq_len, d_model)\n",
    "        num_heads, seq_len, d_k = x.shape\n",
    "        x = x.transpose(1, 0, 2).reshape(seq_len, self.d_model)\n",
    "    def forward(self, Q, K, V):\n",
    "        # linear projection\n",
    "        Q_proj = Q @ self.W_Q\n",
    "        K_proj = K @ self.W_K\n",
    "        V_proj = V @ self.W_V\n",
    "        # Chia thành nhiều head\n",
    "        Q_heads = self.split_heads(Q_proj)\n",
    "        K_heads = self.split_heads(K_proj)\n",
    "        V_heads = self.split_heads(V_proj)\n",
    "        # Attention trên từng head\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            out = scaled_dot_product_attention(Q_heads[i], K_heads[i], V_heads[i])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0aa70c",
   "metadata": {},
   "source": [
    "Pipeline của Encoder trong transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class EncoderLayer:\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        # Residual + layer Normalize (2 lần: sau MHA và sau FFN)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self attention + residual và layer norm\n",
    "        attn_ouput = \n",
    "        x = self.norm(x + attn_ouput)\n",
    "\n",
    "        # ffn + residual và layer norm\n",
    "        ff_output = self.feed_forward.forward(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duong_kernel_2",
   "language": "python",
   "name": "duong_kernel_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
