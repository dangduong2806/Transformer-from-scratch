{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d336d6e3",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8082910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def positional_encoding(max_len, d_model):\n",
    "    # max_len: độ dài tối đa của 1 chuỗi\n",
    "    # d_model: kích thước embedding\n",
    "    pe = np.zeros((max_len, d_model))\n",
    "    for pos in range(max_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            angle = pos / (10000 ** (i / d_model))\n",
    "            # Vị trí chẵn\n",
    "            pe[pos, i] = math.sin(angle)\n",
    "            # Vị trí lẻ\n",
    "            pe[pos, i+1] = math.cos(angle)\n",
    "    return pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f751a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma trận ban đầu:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "------------------\n",
      "ma trận positional encoding:\n",
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      " [ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      " [-0.7568025  -0.65364362  0.03998933  0.99920011]]\n",
      "--------------------------\n",
      "vector PE cho vị trí thứ: 0 là:\n",
      "[0. 1. 0. 1.]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 1 là:\n",
      "[0.84147098 0.54030231 0.00999983 0.99995   ]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 2 là:\n",
      "[ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 3 là:\n",
      "[ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 4 là:\n",
      "[-0.7568025  -0.65364362  0.03998933  0.99920011]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_len = 5\n",
    "d_model = 4\n",
    "pe = np.zeros((5, 4))\n",
    "print(f\"ma trận ban đầu:\\n{pe}\")\n",
    "print(f\"------------------\")\n",
    "for pos in range(max_len):\n",
    "    for i in range(0, d_model, 2):\n",
    "        angle = pos / (10000 ** (i / d_model))\n",
    "        pe[pos][i] = math.sin(angle)\n",
    "        pe[pos][i+1] = math.cos(angle)\n",
    "print(f\"ma trận positional encoding:\\n{pe}\")\n",
    "print(f\"--------------------------\")\n",
    "for i in range(max_len):\n",
    "    print(f\"vector PE cho vị trí thứ: {i} là:\\n{pe[i]}\")\n",
    "    print(f\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51dc3c",
   "metadata": {},
   "source": [
    "Sau khi tính PE, ta cộng vào embedding ban đầu: X' = X + PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a83c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector embedding của input:\n",
      "[[ 0.75207762  0.39295297  0.79099217  1.87580961]\n",
      " [ 0.35367123  0.5852904   1.61532946 -0.90602122]\n",
      " [ 0.74855612  0.69010519 -0.12972793 -1.72377946]\n",
      " [ 2.24647999 -1.12874016 -1.06103864 -1.01515607]\n",
      " [ 0.87578281  0.93191164 -0.57107056  0.27969836]]\n",
      "---------------------------------\n",
      "vector x khi thêm positional encoding:\n",
      "[[ 0.75207762  1.39295297  0.79099217  2.87580961]\n",
      " [ 1.19514222  1.12559271  1.62532929  0.09392878]\n",
      " [ 1.65785354  0.27395836 -0.10972926 -0.72397945]\n",
      " [ 2.3876     -2.11873266 -1.03104314 -0.01560604]\n",
      " [ 0.11898031  0.27826802 -0.53108122  1.27889847]]\n"
     ]
    }
   ],
   "source": [
    "# Giả sử vector X ban đầu có giá trị:\n",
    "x = np.random.randn(max_len, d_model)\n",
    "print(f\"vector embedding của input:\\n{x}\")\n",
    "x = x + pe\n",
    "print(f\"---------------------------------\")\n",
    "print(f\"vector x khi thêm positional encoding:\\n{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf922d",
   "metadata": {},
   "source": [
    "Residual and Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013da2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Layer normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # gamma và beta\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased= False)\n",
    "\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d09530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1:\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
      "gamma2:\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "---------------------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "d_model = 5\n",
    "gamma1 = nn.Parameter(torch.zeros(d_model))\n",
    "gamma2 = torch.zeros(d_model)\n",
    "print(f\"gamma1:\\n{gamma1}\")\n",
    "print(f\"gamma2:\\n{gamma2}\")\n",
    "print(f\"---------------------------\")\n",
    "matrix = torch.zeros(3,4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b39125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7360, -1.2692, -1.3932,  1.6605, -0.7983],\n",
      "         [-0.2400, -1.1686, -0.8228, -0.7886,  0.1682],\n",
      "         [ 0.0861, -1.8974, -1.6468, -1.1555, -1.0670]],\n",
      "\n",
      "        [[ 0.8839, -0.9669,  0.5603,  1.5008,  1.8502],\n",
      "         [-0.0784, -0.8687, -0.4307, -2.7221, -1.1999],\n",
      "         [-0.5919,  0.1197, -1.8306, -1.3393, -0.7754]]])\n",
      "Trung bình của từng hàng: \n",
      "tensor([[[-0.5072],\n",
      "         [-0.5704],\n",
      "         [-1.1362]],\n",
      "\n",
      "        [[ 0.7657],\n",
      "         [-1.0600],\n",
      "         [-0.8835]]])\n",
      "Phương sai của từng hàng:\n",
      "tensor([[[1.2404],\n",
      "         [0.2248],\n",
      "         [0.4679]],\n",
      "\n",
      "        [[0.9549],\n",
      "         [0.8357],\n",
      "         [0.4416]]])\n"
     ]
    }
   ],
   "source": [
    "# Tạo input gồm 2 câu batch_size = 2\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "d_model = 5\n",
    "x = torch.randn(batch_size,seq_len, d_model)\n",
    "print(x)\n",
    "mean = x.mean(dim=-1, keepdim=True)\n",
    "print(f\"Trung bình của từng hàng: \\n{mean}\")\n",
    "var = x.var(dim = -1, keepdim=True, unbiased=False)\n",
    "print(f\"Phương sai của từng hàng:\\n{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7337264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\n",
      "tensor([-0.1824,  0.3139,  1.1220,  0.6295,  1.2129])\n",
      "Chuẩn hóa các giá trị của input:\n",
      "tensor([[[-0.2054, -0.6842, -0.7955,  1.9464, -0.2614],\n",
      "         [ 0.6968, -1.2618, -0.5325, -0.4604,  1.5578],\n",
      "         [ 1.7869, -1.1130, -0.7466, -0.0283,  0.1010]],\n",
      "\n",
      "        [[ 0.1210, -1.7730, -0.2101,  0.7523,  1.1098],\n",
      "         [ 1.0737,  0.2092,  0.6884, -1.8182, -0.1531],\n",
      "         [ 0.4388,  1.5097, -1.4253, -0.6859,  0.1627]]])\n",
      "Đầu ra layernorm của input:\n",
      "tensor([[[-0.1450,  0.0992,  0.2295,  1.8548,  0.8959],\n",
      "         [-0.3096, -0.0822,  0.5245,  0.3397,  3.1024],\n",
      "         [-0.5084, -0.0355,  0.2843,  0.6117,  1.3355]],\n",
      "\n",
      "        [[-0.2045, -0.2427,  0.8862,  1.1031,  2.5590],\n",
      "         [-0.3783,  0.3796,  1.8944, -0.5151,  1.0272],\n",
      "         [-0.2625,  0.7879, -0.4772,  0.1977,  1.4102]]])\n"
     ]
    }
   ],
   "source": [
    "gamma = torch.randn(d_model)\n",
    "print(f\"gamma:\\n{gamma}\")\n",
    "x_hat = (x - mean) / torch.sqrt(var + 1e-6)\n",
    "print(f\"Chuẩn hóa các giá trị của input:\\n{x_hat}\")\n",
    "ans = gamma * x_hat + gamma\n",
    "print(f\"Đầu ra layernorm của input:\\n{ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c54316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sublayer: Feed forward network: 2 hidden layer\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424690fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "d_model = 4\n",
    "d_ff = 6\n",
    "linear1 = nn.Linear(d_model, d_ff)\n",
    "print(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7635e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.3, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.3)\n",
    "print(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd7631",
   "metadata": {},
   "source": [
    "Cài đặt Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c398eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # softmax theo hàng\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x/np.sum(e_x, axis=-1, keepdims=True)\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    # Q: (n, d_k) - n query vectors\n",
    "    # K: (m, d_k) - m key vectors\n",
    "    # V: (m, d_v) - m value vectors\n",
    "    # Lấy ra d_k cho bước tính căn bậc 2\n",
    "    d_k = Q.size(-1)\n",
    "    # Tính score\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "    # Kiểm tra điều kiện để lựa chọn masked attention/self attention\n",
    "    if mask is not None:\n",
    "        # mask = 0 => j <= i\n",
    "        # mask = -inf => j > i\n",
    "        scores = scores + mask\n",
    "    # Tính trọng số attention\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    # Tổ hợp tuyến tính với V\n",
    "    output = np.matmul(weights, V)\n",
    "    print(\"DEBUG - return:\", output.shape, weights.shape)\n",
    "    return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4f050e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9091,  0.2061, -0.4546,  0.6367],\n",
      "        [-1.2448,  0.4964,  1.6776, -0.1488],\n",
      "        [ 0.5368, -0.0883,  0.4763,  0.2788],\n",
      "        [-0.5657, -0.2928, -1.3897, -0.5829]])\n",
      "DEBUG - return: torch.Size([4, 4]) torch.Size([4, 4])\n",
      "tensor([[-1.3124, -0.7470, -0.2218, -0.5469],\n",
      "        [-1.4794, -0.0801, -0.3178, -0.9315],\n",
      "        [-1.3056, -0.7213, -0.4257, -1.0807],\n",
      "        [-0.8558, -0.5707, -0.5549, -0.4428]])\n"
     ]
    }
   ],
   "source": [
    "q = torch.randn(4,4)\n",
    "print(q)\n",
    "k = torch.randn(4,4)\n",
    "v = torch.randn(4,4)\n",
    "ans, weight = scaled_dot_product_attention(q, k , v, mask=None)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2de02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        # d_model phải chia hết cho num_heads\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        # Khởi tạo ma trận trọng số\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        # Ma trận trọng số được sử dụng cuối cùng\n",
    "        self.W_O = nn.Linear(d_model, d_model)\n",
    "    def split_heads(self, x):\n",
    "        # x: (seq_len, d_model)\n",
    "        # return: (num_heads, seq_len, d_k)\n",
    "        seq_len = x.shape[0]\n",
    "        # Tách X thành 1 mảng gồm seq_len ma trận, mỗi ma trận có num_heads hàng, d_k cột\n",
    "        x = x.reshape(seq_len, self.num_heads, self.d_k)\n",
    "        x = x.transpose(1, 0, 2)\n",
    "        return x\n",
    "    def combine_heads(self, x):\n",
    "        # x: (num_heads, seq_len, d_k)\n",
    "        # return: (seq_len, d_model)\n",
    "        num_heads, seq_len, d_k = x.shape\n",
    "        x = x.transpose(1, 0, 2).reshape(seq_len, self.d_model)\n",
    "        return x\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # linear projection\n",
    "        Q_proj = self.W_Q(Q)\n",
    "        K_proj = self.W_K(K)\n",
    "        V_proj = self.W_V(V)\n",
    "        # Chia thành nhiều head\n",
    "        Q_heads = self.split_heads(Q_proj)\n",
    "        K_heads = self.split_heads(K_proj)\n",
    "        V_heads = self.split_heads(V_proj)\n",
    "        # Attention trên từng head\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            out, weights = scaled_dot_product_attention(Q_heads[i], K_heads[i], V_heads[i],mask=mask)\n",
    "            head_outputs.append(out)\n",
    "         # Chuyển đổi sang numpy\n",
    "        head_outputs = np.array(head_outputs)\n",
    "        #Ghép lại các head\n",
    "        concat_output = self.combine_heads(head_outputs)\n",
    "        #Linear cuối\n",
    "        output = np.matmul(concat_output, self.W_O)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0aa70c",
   "metadata": {},
   "source": [
    "Pipeline của Encoder trong transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc5ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class EncoderLayer:\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        # Residual + layer Normalize (2 lần: sau MHA và sau FFN)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self attention + residual và layer norm\n",
    "        attn_ouput = self.self_attn.forward(x, x, x)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        attn_ouput = torch.from_numpy(attn_ouput).float()\n",
    "        x = self.norm1(x + attn_ouput)\n",
    "\n",
    "        # ffn + residual và layer norm\n",
    "        ff_output = self.feed_forward.forward(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e0e237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[-0.07509377 -0.3698525  -0.22432049  1.0959547   0.01523754  0.96403111\n",
      "   0.02157748  0.4108375   0.25443107]\n",
      " [ 0.0676794   1.01323695 -0.93309202  2.40139986 -0.14957959  0.28381189\n",
      "   0.5762631   0.10601228  1.40813583]\n",
      " [-0.03030701 -0.21323273  0.35084385  1.61485775 -1.21254393  0.26825369\n",
      "  -1.2500518   0.10461103  0.92282904]\n",
      " [ 0.95577117  0.33804922  0.44740942 -2.00273896 -1.72381536  0.29851096\n",
      "   0.90978136  2.21275475  1.40961909]\n",
      " [-1.76709122 -0.60497435 -0.38778948 -0.54013972  1.06609982  0.28589675\n",
      "  -1.77708134  0.40230019 -1.2294474 ]]\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_model = 5, 9\n",
    "d_ff = 16\n",
    "num_heads = 3\n",
    "# input\n",
    "x = np.random.randn(seq_len, d_model)\n",
    "print(f\"input:\\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "236f51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - return: (5, 3) (5, 5)\n",
      "DEBUG - return: (5, 3) (5, 5)\n",
      "DEBUG - return: (5, 3) (5, 5)\n",
      "output:\n",
      "tensor([[ 1.1378, -0.0626, -1.1250,  0.7099,  0.2746, -0.5009, -0.4574, -1.6307,\n",
      "          1.6544],\n",
      "        [ 0.3400,  0.6331,  0.8598,  1.0983, -1.5449, -1.0693, -0.7974,  1.3024,\n",
      "         -0.8221],\n",
      "        [ 1.5158,  0.8121, -1.7491, -0.2766, -0.0488,  0.5146, -1.5276,  0.2849,\n",
      "          0.4747],\n",
      "        [ 1.3896,  0.7909, -1.0754,  0.0485, -0.4628,  0.2025, -2.0191,  0.1638,\n",
      "          0.9621],\n",
      "        [ 1.1174, -0.2628, -0.7621, -0.6514,  1.1118, -0.6572,  0.5800, -1.7477,\n",
      "          1.2721]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encoder layer\n",
    "encoder_layer = EncoderLayer(d_model, d_ff, num_heads=num_heads)\n",
    "# Forward\n",
    "output = encoder_layer.forward(x)\n",
    "print(f\"output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425725b",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Attention\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def generate_subsequent_mask(seq_len):\n",
    "    # Tạo mask tam giác dưới: (seq_len, seq_len)\n",
    "    # 1. Tạo ma trận toàn 1 (seq_len, seq_len)\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len), diagnol= 1)\n",
    "    # 2. Các phần tử bằng 1 được thay bằng -inf\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f1b65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma trận Q:\n",
      "tensor([[[ 2.0861,  0.9458,  0.1764, -0.4620],\n",
      "         [ 0.6028, -1.5721, -0.3679,  0.2793],\n",
      "         [-0.9556, -0.5626, -2.6054,  1.1850],\n",
      "         [ 0.2986,  2.6248, -1.9058,  1.1733],\n",
      "         [-1.5534, -0.9213, -0.5887,  0.7975]],\n",
      "\n",
      "        [[ 0.2087, -1.1785,  0.2484,  0.4529],\n",
      "         [ 1.6350,  0.8900, -1.3365, -0.3949],\n",
      "         [ 2.0959,  0.0076,  0.4040, -0.6172],\n",
      "         [ 0.4017,  0.3683,  1.4506,  0.1693],\n",
      "         [-0.9754,  0.3130,  0.6612, -0.0763]]])\n",
      "size of Q: torch.Size([2, 5, 4])\n",
      "Softmax theo từng hàng của ma trận Q:\n",
      "tensor([[[0.6468, 0.2068, 0.0958, 0.0506],\n",
      "         [0.4512, 0.0513, 0.1709, 0.3265],\n",
      "         [0.0895, 0.1325, 0.0172, 0.7608],\n",
      "         [0.0727, 0.7448, 0.0080, 0.1744],\n",
      "         [0.0625, 0.1176, 0.1640, 0.6559]],\n",
      "\n",
      "        [[0.2804, 0.0700, 0.2917, 0.3579],\n",
      "         [0.6034, 0.2864, 0.0309, 0.0793],\n",
      "         [0.7276, 0.0901, 0.1340, 0.0483],\n",
      "         [0.1781, 0.1723, 0.5084, 0.1412],\n",
      "         [0.0818, 0.2968, 0.4203, 0.2011]]])\n"
     ]
    }
   ],
   "source": [
    "d_k, d_v = 4, 8\n",
    "batch_size, seq_len = 2, 5\n",
    "Q = torch.randn(batch_size, seq_len, d_k)\n",
    "print(f\"ma trận Q:\\n{Q}\")\n",
    "print(f\"size of Q: {Q.size()}\")\n",
    "K = torch.randn(batch_size, seq_len, d_k)\n",
    "V = torch.randn(batch_size, seq_len, d_v)\n",
    "weights = F.softmax(Q, dim= -1)\n",
    "print(f\"Softmax theo từng hàng của ma trận Q:\\n{weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac2ccdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:\n",
      "tensor([[0., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "mask sau thay đổi:\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.ones(seq_len, seq_len)\n",
    "mask = torch.triu(matrix, diagonal= 1)\n",
    "print(f\"mask:\\n{mask}\")\n",
    "mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "print(f\"mask sau thay đổi:\\n{mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aee30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 0, 'go': 1, 'to': 2, 'the': 3, 'park': 4, 'near': 5, 'my': 6, 'house': 7}\n",
      "{0: 'I', 1: 'go', 2: 'to', 3: 'the', 4: 'park', 5: 'near', 6: 'my', 7: 'house'}\n",
      "Ma trận embedding của input:\n",
      "tensor([[-0.8859,  0.2058,  1.1791,  0.0449,  0.4983,  1.0668],\n",
      "        [ 0.8939, -0.5181, -0.9900, -0.1671, -1.0639,  0.6621],\n",
      "        [ 0.4418,  1.5516, -0.4362,  1.4317, -0.3831,  0.9559],\n",
      "        [-1.2453, -0.5026,  0.1953, -1.1089, -1.2330, -0.6130],\n",
      "        [ 1.5907,  0.6140, -1.6030, -1.1067,  1.7049, -0.2767],\n",
      "        [ 0.1596, -0.2986,  1.3326, -0.0433, -0.0813,  0.1333],\n",
      "        [ 2.3909,  0.7044,  0.1906, -0.0279,  0.8173, -0.7082],\n",
      "        [-1.3154,  1.1149,  0.6866, -0.2226,  1.6634, -0.6156]])\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra với input cụ thể\n",
    "text = [\"I\", \"go\", \"to\", \"the\", \"park\", \"near\", \"my\", \"house\"]\n",
    "c2i = {ch:i for i, ch in enumerate(text)}\n",
    "print(c2i)\n",
    "i2c = {i:ch for ch, i in c2i.items()}\n",
    "print(i2c)\n",
    "seq_len = len(text)\n",
    "d_model = 6\n",
    "embedding_matrix = torch.randn(seq_len, d_model)\n",
    "print(f\"Ma trận embedding của input:\\n{embedding_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6768609",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 8\n",
    "W_Q = torch.randn(d_model, d_k)\n",
    "W_K = torch.randn(d_model, d_k)\n",
    "W_V = torch.randn(d_model, d_v)\n",
    "# Ma trận Q, K, V\n",
    "Q = torch.matmul(embedding_matrix, W_Q)\n",
    "K = torch.matmul(embedding_matrix, W_K)\n",
    "V = torch.matmul(embedding_matrix, W_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6751fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDecoderLayer\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, num_heads, d_ff, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads) # masked attention\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    # self_mask -> masked attention\n",
    "    # enc_mask -> self attention\n",
    "    def forward(self, x, enc_out, self_mask=None, enc_mask=None):\n",
    "        # x: decoder input embeddings (B, T_dec, d_model)\n",
    "        # enc_out: encoder outputs (B, T_enc, d_model)\n",
    "        \n",
    "        # 1, masked self-attention (queries=keys=values = x)\n",
    "        residual = x\n",
    "        # sublayer\n",
    "        attn_out, self_attn_map = self.self_attn(x, x, x, self_mask)\n",
    "        x = residual + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        # 2, encoder-decoder attention (queries from x, keys/values from enc_out)\n",
    "        residual = x\n",
    "        attn_out2, encdec_attn_map = self.enc_dec_attn(x, enc_out, enc_out, enc_mask)\n",
    "        x = residual + self.dropout(attn_out2)\n",
    "        x = self.norm2(x)\n",
    "        # 3, feed-forward\n",
    "        residual = x\n",
    "        ff_out = self.ff(x)\n",
    "        x = residual + self.dropout(ff_out)\n",
    "        x = self.norm3(x)\n",
    "\n",
    "        return x, self_attn_map, encdec_attn_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a31eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, max_len = 10, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # Tạo num_layers lớp Decoderlayer\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(DecoderLayer(d_model=d_model, num_heads=num_heads, d_ff=d_ff, dropout=dropout))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, tgt_tokens, enc_out, tgt_mask=None, enc_mask=None):\n",
    "        # tgt_tokens: (B, T_dec) token ids\n",
    "        B, T = tgt_tokens.size() # Batch, T tokens\n",
    "        # Positinal encoding\n",
    "        positions = torch.arange(0, T, device=tgt_tokens.device).unsqueeze(0).expand(B, T)\n",
    "        x = self.token_emb(tgt_tokens) * math.sqrt(self.d_model) + self.pos_emb(positions)\n",
    "\n",
    "        attn_maps = {\"masked_self\": [], \"encdec\": []}\n",
    "        for layer in self.layers:\n",
    "            x, masked_map, encdec_map = layer(x, enc_out, self_mask=tgt_mask, enc_mask=enc_mask)\n",
    "            attn_maps[\"masked_self\"].append(masked_map)\n",
    "            attn_maps[\"encdec\"].append(encdec_map)\n",
    "        # Chuẩn hóa trước khi đưa vào linear + softmax để sinh từ.\n",
    "        x = self.norm(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duong_kernel_2",
   "language": "python",
   "name": "duong_kernel_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
