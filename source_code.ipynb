{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d336d6e3",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8082910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def positional_encoding(max_len, d_model):\n",
    "    # max_len: độ dài tối đa của 1 chuỗi\n",
    "    # d_model: kích thước embedding\n",
    "    pe = np.zeros((max_len, d_model))\n",
    "    for pos in range(max_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            angle = pos / (10000 ** (i / d_model))\n",
    "            # Vị trí chẵn\n",
    "            pe[pos, i] = math.sin(angle)\n",
    "            # Vị trí lẻ\n",
    "            pe[pos, i+1] = math.cos(angle)\n",
    "    return pe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f751a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma trận ban đầu:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "------------------\n",
      "ma trận positional encoding:\n",
      "[[ 0.          1.          0.          1.        ]\n",
      " [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      " [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      " [ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      " [-0.7568025  -0.65364362  0.03998933  0.99920011]]\n",
      "--------------------------\n",
      "vector PE cho vị trí thứ: 0 là:\n",
      "[0. 1. 0. 1.]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 1 là:\n",
      "[0.84147098 0.54030231 0.00999983 0.99995   ]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 2 là:\n",
      "[ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 3 là:\n",
      "[ 0.14112001 -0.9899925   0.0299955   0.99955003]\n",
      "------------------------------\n",
      "vector PE cho vị trí thứ: 4 là:\n",
      "[-0.7568025  -0.65364362  0.03998933  0.99920011]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_len = 5\n",
    "d_model = 4\n",
    "pe = np.zeros((5, 4))\n",
    "print(f\"ma trận ban đầu:\\n{pe}\")\n",
    "print(f\"------------------\")\n",
    "for pos in range(max_len):\n",
    "    for i in range(0, d_model, 2):\n",
    "        angle = pos / (10000 ** (i / d_model))\n",
    "        pe[pos][i] = math.sin(angle)\n",
    "        pe[pos][i+1] = math.cos(angle)\n",
    "print(f\"ma trận positional encoding:\\n{pe}\")\n",
    "print(f\"--------------------------\")\n",
    "for i in range(max_len):\n",
    "    print(f\"vector PE cho vị trí thứ: {i} là:\\n{pe[i]}\")\n",
    "    print(f\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51dc3c",
   "metadata": {},
   "source": [
    "Sau khi tính PE, ta cộng vào embedding ban đầu: X' = X + PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61a83c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector embedding của input:\n",
      "[[-2.51048054  0.91427526  0.38544417 -1.15885041]\n",
      " [ 0.1372257   0.11977357 -0.25662949 -0.51509956]\n",
      " [-2.48507099 -2.04366644 -0.92723553  0.24973802]\n",
      " [-0.40296381 -0.20171841  1.82388598  1.63357139]\n",
      " [-0.31936225  1.30005329 -0.19187889  0.0853536 ]]\n",
      "---------------------------------\n",
      "vector x khi thêm positional encoding:\n",
      "[[-2.51048054  1.91427526  0.38544417 -0.15885041]\n",
      " [ 0.97869668  0.66007587 -0.24662966  0.48485044]\n",
      " [-1.57577356 -2.45981328 -0.90723687  1.24953802]\n",
      " [-0.2618438  -1.19171091  1.85388148  2.63312142]\n",
      " [-1.07616475  0.64640967 -0.15188955  1.08455371]]\n"
     ]
    }
   ],
   "source": [
    "# Giả sử vector X ban đầu có giá trị:\n",
    "x = np.random.randn(max_len, d_model)\n",
    "print(f\"vector embedding của input:\\n{x}\")\n",
    "x = x + pe\n",
    "print(f\"---------------------------------\")\n",
    "print(f\"vector x khi thêm positional encoding:\\n{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffcdde",
   "metadata": {},
   "source": [
    "Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf922d",
   "metadata": {},
   "source": [
    "Residual and Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "013da2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Layer normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # gamma và beta\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased= False)\n",
    "\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * x_hat + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0d09530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1:\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
      "gamma2:\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "---------------------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "d_model = 5\n",
    "gamma1 = nn.Parameter(torch.zeros(d_model))\n",
    "gamma2 = torch.zeros(d_model)\n",
    "print(f\"gamma1:\\n{gamma1}\")\n",
    "print(f\"gamma2:\\n{gamma2}\")\n",
    "print(f\"---------------------------\")\n",
    "matrix = torch.zeros(3,4)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9b39125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5954, -1.0103,  0.0845,  0.7275,  0.0063],\n",
      "         [ 0.2819, -2.6054, -0.3287, -1.2705, -2.9631],\n",
      "         [ 1.1723, -0.9449,  1.3273,  1.0438, -1.9599]],\n",
      "\n",
      "        [[ 1.6810, -0.8743, -1.0050,  0.3031, -0.1766],\n",
      "         [-0.5185, -0.0095,  0.7464,  1.5546, -0.7502],\n",
      "         [ 0.0041, -0.7962,  1.2341,  0.0677, -0.5324]]])\n",
      "Trung bình của từng hàng: \n",
      "tensor([[[-0.3575],\n",
      "         [-1.3772],\n",
      "         [ 0.1277]],\n",
      "\n",
      "        [[-0.0144],\n",
      "         [ 0.2045],\n",
      "         [-0.0045]]])\n",
      "Phương sai của từng hàng:\n",
      "tensor([[[0.6927],\n",
      "         [1.5774],\n",
      "         [1.7756]],\n",
      "\n",
      "        [[0.9444],\n",
      "         [0.7193],\n",
      "         [0.4890]]])\n"
     ]
    }
   ],
   "source": [
    "# Tạo input gồm 2 câu batch_size = 2\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "d_model = 5\n",
    "x = torch.randn(batch_size,seq_len, d_model)\n",
    "print(x)\n",
    "mean = x.mean(dim=-1, keepdim=True)\n",
    "print(f\"Trung bình của từng hàng: \\n{mean}\")\n",
    "var = x.var(dim = -1, keepdim=True, unbiased=False)\n",
    "print(f\"Phương sai của từng hàng:\\n{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7337264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\n",
      "tensor([-0.1320,  0.4723,  1.3455,  0.8358, -1.9937])\n",
      "Chuẩn hóa các giá trị của input:\n",
      "tensor([[[-1.4874, -0.7843,  0.5311,  1.3036,  0.4370],\n",
      "         [ 1.3210, -0.9780,  0.8348,  0.0849, -1.2627],\n",
      "         [ 0.7839, -0.8050,  0.9003,  0.6875, -1.5667]],\n",
      "\n",
      "        [[ 1.7445, -0.8849, -1.0194,  0.3266, -0.1669],\n",
      "         [-0.8526, -0.2524,  0.6389,  1.5918, -1.1258],\n",
      "         [ 0.0124, -1.1321,  1.7713,  0.1033, -0.7549]]])\n",
      "Đầu ra layernorm của input:\n",
      "tensor([[[ 0.0643,  0.1019,  2.0601,  1.9254, -2.8650],\n",
      "         [-0.3064,  0.0104,  2.4687,  0.9068,  0.5238],\n",
      "         [-0.2355,  0.0921,  2.5568,  1.4104,  1.1297]],\n",
      "\n",
      "        [[-0.3623,  0.0544, -0.0261,  1.1088, -1.6609],\n",
      "         [-0.0195,  0.3531,  2.2051,  2.1663,  0.2508],\n",
      "         [-0.1336, -0.0624,  3.7289,  0.9221, -0.4887]]])\n"
     ]
    }
   ],
   "source": [
    "gamma = torch.randn(d_model)\n",
    "print(f\"gamma:\\n{gamma}\")\n",
    "x_hat = (x - mean) / torch.sqrt(var + 1e-6)\n",
    "print(f\"Chuẩn hóa các giá trị của input:\\n{x_hat}\")\n",
    "ans = gamma * x_hat + gamma\n",
    "print(f\"Đầu ra layernorm của input:\\n{ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79c54316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sublayer: Feed forward network: 2 hidden layer\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "424690fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "d_model = 4\n",
    "d_ff = 6\n",
    "linear1 = nn.Linear(d_model, d_ff)\n",
    "print(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "370ee596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual connection Layernorm\n",
    "class SublayerConnection(nn.Module):\n",
    "    # y = layernorm(x + sublayer(x))\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, sublayer):\n",
    "        output = self.norm(x + self.dropout(sublayer(x)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7635e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.3, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.3)\n",
    "print(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "09c90af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[[ 0.3565,  0.9443, -1.1438, -0.2553, -1.4977, -0.3394],\n",
      "         [ 0.0317, -1.2267, -1.8146,  0.2450,  0.4963, -0.2686],\n",
      "         [-0.0608,  0.9713, -0.1718,  0.7234,  0.2029,  0.8809],\n",
      "         [-0.8522,  0.6999,  1.6019,  2.5095,  0.4683, -1.1485]]])\n",
      "output của x khi đi qua residual + layer normalization:\n",
      "tensor([[[ 6.4081e-01,  1.6274e+00, -7.7806e-01, -1.7715e-01, -1.5057e+00,\n",
      "           1.9266e-01],\n",
      "         [ 3.5039e-01, -9.5322e-01, -1.7534e+00,  7.3252e-01,  9.5247e-01,\n",
      "           6.7120e-01],\n",
      "         [-1.0468e+00,  1.1493e+00, -1.2594e+00, -9.7621e-02, -1.4764e-01,\n",
      "           1.4021e+00],\n",
      "         [-1.0436e+00, -6.4312e-05,  1.0593e+00,  1.3934e+00, -5.0756e-02,\n",
      "          -1.3582e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# y = layernorm(x + sublayer(x))\n",
    "# Giả sử input x là 1 câu có 4 từ, mỗi từ được mã hóa thành vector 6 chiều\n",
    "# ma trận embedding\n",
    "x = torch.randn(1, 4, 6)\n",
    "print(f\"input:\\n{x}\")\n",
    "sublayer = FeedForward(d_model=6, d_ff=10)\n",
    "sublayer_connection = SublayerConnection(6)\n",
    "y = sublayer_connection(x, sublayer)\n",
    "print(f\"output của x khi đi qua residual + layer normalization:\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd7631",
   "metadata": {},
   "source": [
    "Cài đặt MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c398eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # softmax theo hàng\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x/np.sum(e_x, axis=-1, keepdims=True)\n",
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    # Q: (n, d_k) - n query vectors\n",
    "    # K: (m, d_k) - m key vectors\n",
    "    # V: (m, d_v) - m value vectors\n",
    "    # Lấy ra d_k cho bước tính căn bậc 2\n",
    "    d_k = Q.shape[1]\n",
    "    # Tính score\n",
    "    scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n",
    "    # Tính trọng số attention\n",
    "    weights = softmax(scores)\n",
    "    # Tổ hợp tuyến tính với V\n",
    "    output = np.matmul(weights, V)\n",
    "    print(\"DEBUG - return:\", output.shape, weights.shape)\n",
    "    return output, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4f050e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - return: (4, 4) (4, 4)\n",
      "[[ 0.31239633  0.09678679 -0.68516955  1.13982061]\n",
      " [ 0.24402395 -0.19830626 -0.75061639  0.99637655]\n",
      " [-0.23419394 -0.36439287 -0.31383449  0.85832369]\n",
      " [-0.22604182 -0.41325785 -0.21459471  0.63481584]]\n"
     ]
    }
   ],
   "source": [
    "q = np.random.randn(4, 4)\n",
    "k = np.random.randn(4, 4)\n",
    "v = np.random.randn(4, 4)\n",
    "ans, weight = scaled_dot_product_attention(q, k , v)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f2de02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        # d_model phải chia hết cho num_heads\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        # Khởi tạo ma trận trọng số\n",
    "        self.W_Q = np.random.randn(d_model, d_model)\n",
    "        self.W_K = np.random.randn(d_model, d_model)\n",
    "        self.W_V = np.random.randn(d_model, d_model)\n",
    "        # Ma trận trọng số được sử dụng cuối cùng\n",
    "        self.W_O = np.random.randn(d_model, d_model)\n",
    "    def split_heads(self, x):\n",
    "        # x: (seq_len, d_model)\n",
    "        # return: (num_heads, seq_len, d_k)\n",
    "        seq_len = x.shape[0]\n",
    "        # Tách X thành 1 mảng gồm seq_len ma trận, mỗi ma trận có num_heads hàng, d_k cột\n",
    "        x = x.reshape(seq_len, self.num_heads, self.d_k)\n",
    "        x = x.transpose(1, 0, 2)\n",
    "        return x\n",
    "    def combine_heads(self, x):\n",
    "        # x: (num_heads, seq_len, d_k)\n",
    "        # return: (seq_len, d_model)\n",
    "        num_heads, seq_len, d_k = x.shape\n",
    "        x = x.transpose(1, 0, 2).reshape(seq_len, self.d_model)\n",
    "        return x\n",
    "    def forward(self, Q, K, V):\n",
    "        # linear projection\n",
    "        Q_proj = Q @ self.W_Q\n",
    "        K_proj = K @ self.W_K\n",
    "        V_proj = V @ self.W_V\n",
    "        # Chia thành nhiều head\n",
    "        Q_heads = self.split_heads(Q_proj)\n",
    "        K_heads = self.split_heads(K_proj)\n",
    "        V_heads = self.split_heads(V_proj)\n",
    "        # Attention trên từng head\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            out, weights = scaled_dot_product_attention(Q_heads[i], K_heads[i], V_heads[i])\n",
    "            head_outputs.append(out)\n",
    "         # Chuyển đổi sang numpy\n",
    "        head_outputs = np.array(head_outputs)\n",
    "        #Ghép lại các head\n",
    "        concat_output = self.combine_heads(head_outputs)\n",
    "        #Linear cuối\n",
    "        output = np.matmul(concat_output, self.W_O)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0aa70c",
   "metadata": {},
   "source": [
    "Pipeline của Encoder trong transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ebc5ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class EncoderLayer:\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        # Residual + layer Normalize (2 lần: sau MHA và sau FFN)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self attention + residual và layer norm\n",
    "        attn_ouput = self.self_attn.forward(x, x, x)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        attn_ouput = torch.from_numpy(attn_ouput).float()\n",
    "        x = self.norm1(x + attn_ouput)\n",
    "\n",
    "        # ffn + residual và layer norm\n",
    "        ff_output = self.feed_forward.forward(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3e0e237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[ 0.77472802 -0.08647975 -1.45733034  0.74714996 -0.77795334 -0.49143968\n",
      "  -0.58541248  0.35992965  0.60493472]\n",
      " [ 1.43347545 -0.33980881  1.87000663 -1.05037168  0.79688901 -1.33239766\n",
      "  -1.62198809 -0.48038467  1.2206296 ]\n",
      " [ 0.77125802  1.93978138  0.19991508 -0.53569585 -1.51229057 -1.20003037\n",
      "   0.39999264 -0.22251599 -0.1348209 ]\n",
      " [-1.1684963  -0.26625375 -1.12345459 -1.07408403  0.2065336   1.14968316\n",
      "   0.14735544 -1.31236736 -1.63588371]\n",
      " [-1.19218815  0.87773835 -1.23193794  1.35666971  1.23455314  1.28359339\n",
      "  -1.7580598  -0.55558014  1.41733379]]\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_model = 5, 9\n",
    "d_ff = 16\n",
    "num_heads = 3\n",
    "# input\n",
    "x = np.random.randn(seq_len, d_model)\n",
    "print(f\"input:\\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "236f51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - return: (5, 3) (5, 5)\n",
      "DEBUG - return: (5, 3) (5, 5)\n",
      "DEBUG - return: (5, 3) (5, 5)\n",
      "output:\n",
      "tensor([[ 0.1950,  0.4481, -0.7200, -0.2458, -0.1987,  1.3861, -0.7900,  1.6352,\n",
      "         -1.7099],\n",
      "        [-0.6894,  0.5175,  0.6528, -1.1169,  1.1802,  0.7534,  0.2656,  0.5087,\n",
      "         -2.0720],\n",
      "        [ 0.0608,  0.1853,  0.4344, -0.2785,  0.0940,  1.1306, -0.6521,  1.3168,\n",
      "         -2.2912],\n",
      "        [-1.8131,  1.3276, -1.1554, -0.5013, -0.0845,  0.9658,  0.3745, -0.2242,\n",
      "          1.1106],\n",
      "        [ 0.3105,  0.4312,  0.3239, -0.2927,  0.5611,  1.0954, -0.8275,  0.7872,\n",
      "         -2.3891]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encoder layer\n",
    "encoder_layer = EncoderLayer(d_model, d_ff, num_heads=num_heads)\n",
    "# Forward\n",
    "output = encoder_layer.forward(x)\n",
    "print(f\"output:\\n{output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duong_kernel_2",
   "language": "python",
   "name": "duong_kernel_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
